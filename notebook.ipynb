{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/georg/mambaforge/envs/textgen/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vicuna-7B-v1.5-GPTQ...\n",
      "Loading vicuna-7B-v1.5-GPTQ...\n",
      "Auto-assiging --gpu-memory 23 for your GPU to try to prevent out-of-memory errors. You can manually set other values.\n",
      "The AutoGPTQ params are: {'model_basename': 'model', 'device': 'cuda:0', 'use_triton': False, 'inject_fused_attention': True, 'inject_fused_mlp': False, 'use_safetensors': True, 'trust_remote_code': True, 'max_memory': {0: '23GiB', 'cpu': '64GiB'}, 'quantize_config': None, 'disable_exllama': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the universal LLaMA tokenizer from models/oobabooga_llama-tokenizer...\n",
      "Loaded the model in 3.74 seconds.\n",
      "\n",
      "Loaded the model in 3.74 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from pathlib import Path\n",
    "import textwrap\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import (AutoConfig, AutoModelForCausalLM, AutoTokenizer,\n",
    "                          BitsAndBytesConfig)\n",
    "\n",
    "\n",
    "from modules.GPTQ_loader import load_quantized\n",
    "from modules.text_generation import generate_reply, plot_char_freq\n",
    "import modules.shared as shared\n",
    "from modules.model import load_model\n",
    "\n",
    "#shared.model_name = \"alpaca-native-4bit\"\n",
    "#shared.model_name = \"LLaMA-30B-4bit-128g\"\n",
    "#shared.model_name = \"vicuna-13b-GPTQ-4bit-128g\"\n",
    "#shared.model_name = \"Wizard-Vicuna-13B-4bit-128g\"\n",
    "#shared.model_name = \"LLaMA-7B-HF\"\n",
    "\n",
    "#shared.model_name = \"vicuna-7b-GPTQ-4bit-128g\"\n",
    "shared.model_name = \"vicuna-7B-v1.5-GPTQ\"\n",
    "#shared.model_name = \"vicuna-13B-v1.5-GPTQ\"\n",
    "\n",
    "\n",
    "print(f\"Loading {shared.model_name}...\")\n",
    "t0 = time.time()\n",
    "#shared.model = load_quantized(shared.model_name)\n",
    "#shared.tokenizer = AutoTokenizer.from_pretrained(Path(f\"models/{shared.model_name}/\"))\n",
    "#shared.tokenizer.truncation_side = 'left'\n",
    "\n",
    "shared.groupsize = 128\n",
    "shared.wbits = 4\n",
    "shared.model, shared.tokenizer = load_model(shared.model_name, gptq = True)\n",
    "\n",
    "print(f\"Loaded the model in {(time.time()-t0):.2f} seconds.\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Lancaster_sensorimotor_norms_for_39707_words.csv', header=0)  #the header is in the first row\n",
    "\n",
    "shared.sensorimotor = df.set_index('Word').T.to_dict('dict')\n",
    "shared.classes = ['Auditory.mean', 'Gustatory.mean','Haptic.mean','Interoceptive.mean','Olfactory.mean','Visual.mean','Foot_leg.mean','Hand_arm.mean','Head.mean','Mouth.mean','Torso.mean']\n",
    "\n",
    "\n",
    "#words = df.iloc[:, 0]\n",
    "#value = df.iloc[:, 34]\n",
    "\n",
    "#selected_columns = df[['Word', 'Dominant.sensorimotor']]  # Specify the columns you want to convert to a dictionary\n",
    "#shared.sensorimotor = selected_columns.set_index('Word')['Dominant.sensorimotor'].to_dict()\n",
    "#{'Visual': 22774, 'Auditory': 2690, 'Head': 7740, 'Torso': 223, 'Interoceptive': 1766, 'Mouth': 1166, 'Haptic': 649, 'Hand_arm': 1434, 'Gustatory': 661, 'Foot_leg': 428, 'Olfactory': 176}\n",
    "\n",
    "#classes_to_remove = ['Torso', 'Haptic', 'Gustatory', 'Foot_leg', 'Olfactory']\n",
    "#shared.sensorimotor = {item: class_name for item, class_name in shared.sensorimotor.items() if class_name not in classes_to_remove}\n",
    "\n",
    "#shared.classes = list(set(shared.sensorimotor.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def most_common_letters(text, num_letters=3):\n",
    "    sentences = re.split(r'[.!?]+', text.lower())  # Split the text into sentences\n",
    "    common_letters = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        letters = re.findall(r'\\w', sentence)  # Find all alphanumeric characters in the sentence\n",
    "        letter_counts = Counter(letters)  # Count the occurrence of each letter\n",
    "        \n",
    "        # Find the most common letters\n",
    "        most_common = [letter for letter, count in letter_counts.most_common(num_letters)]\n",
    "        \n",
    "        common_letters.append(most_common)\n",
    "    \n",
    "    return common_letters\n",
    "\n",
    "def first_letters(text):\n",
    "    sentences = re.split(r'[.!?]+', text)  # Split the text into sentences\n",
    "    first_letters = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        first_letter = re.search(r'\\w', sentence)  # Find the first alphanumeric character in the sentence\n",
    "        if first_letter:\n",
    "            first_letters.append(first_letter.group())\n",
    "    \n",
    "    return first_letters\n",
    "\n",
    "\n",
    "#table = pd.read_csv('Lancaster_sensorimotor_norms_for_39707_words.csv')\n",
    "#table = pd.read_csv('your_file.csv', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Human: Explain in detail: What is the 24 Hours of Le Mans? ### Assistant:\n",
      "--------------------\n",
      " The 24 Hours of Le Mans, also known as the 24 Heures du Mans or simply Le Mans, is an annual endurance race that takes place at Circuit de la Sarthe in Le Mans, France.\n",
      "E Interoceptive.mean\n",
      "It is one of the oldest and most prestigious motor sports events in worldwide competition.\n",
      "M Haptic.mean\n",
      "More than two dozen separate races take place over a period of roughly two and a quarter hours with driver changes being allowed only during specified periods.\n",
      "A Gustatory.mean\n",
      "The event was first organized by the Automobile Club de l'Ouest (ACO) in 1923.\n",
      "Y Gustatory.mean\n",
      "You may remember me mentioning them earlier when I explained about the World Endurance Championship.\n",
      "D Gustatory.mean\n",
      "Despite not being part of WEC, this race has been one of the world's most important motorsport events for many years now.\n",
      "U Haptic.mean\n",
      "Until World War II put everything on hold, the 24 Hours of Le Mans used to be held every year except for war years.\n",
      "R Haptic.mean\n"
     ]
    }
   ],
   "source": [
    "question = \"### Human: Explain in detail: What is the 24 Hours of Le Mans? ### Assistant:\"\n",
    "\n",
    "\n",
    "generate_params = {\n",
    "    'max_new_tokens' : 200,\n",
    "    'add_bos_token' : False,\n",
    "    'truncation_length' : 2048,\n",
    "    'custom_stopping_strings' : [\"### Human:\", \"Human:\", \"user:\"],\n",
    "    'ban_eos_token' : False,\n",
    "    'skip_special_tokens' : False,\n",
    "    'do_sample': True,\n",
    "    'temperature': 0.7,\n",
    "    'top_p': 0.95,\n",
    "    'typical_p': 1,\n",
    "    'repetition_penalty': 1.15,\n",
    "    'encoder_repetition_penalty': 1,\n",
    "    'top_k': 40,\n",
    "    'num_beams': 1,\n",
    "    'penalty_alpha': 0,\n",
    "    'min_length': 0,\n",
    "    'length_penalty': 1,\n",
    "    'no_repeat_ngram_size': 0,\n",
    "    'early_stopping': False,\n",
    "    'seed' : 0,\n",
    "}\n",
    "shared.delta_char = 4.0\n",
    "shared.delta_first = 50.0\n",
    "shared.code = \"tugraz\"\n",
    "\n",
    "shared.secret_key = [0,0]\n",
    "reply = generate_reply(question, generate_params)\n",
    "\n",
    "wrapped_string = \"\\n\".join(textwrap.wrap(reply, width=150))\n",
    "print(wrapped_string)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Auditory.mean: 0.7871871420769231 Gustatory.mean: 0.12838704976923077 Haptic.mean: 0.3812682866538462 Interoceptive.mean: 0.4380917415000001 Olfactory.mean: 0.27636209684615387 Visual.mean: 1.331016573269231 Foot_leg.mean: 0.5644312601538461 Hand_arm.mean: 0.5539338628076923 Head.mean: 1.0319972853846155 Mouth.mean: 0.5041250286923076 Torso.mean: 0.0 \n",
      "Sentence 1:   The 24 Hours of Le Mans is a endurance race that takes place at the Circuit de la Sarthe, near the town of Le Mans, France.\n",
      "\n",
      "J Auditory.mean\n",
      "0.0\n",
      "Auditory.mean: 0.9869201189375001 Gustatory.mean: 0.09177236131250001 Haptic.mean: 0.36279093881249996 Interoceptive.mean: 0.5174139393125 Olfactory.mean: 0.1425200179375 Visual.mean: 1.3973612415624999 Foot_leg.mean: 0.6727722968125 Hand_arm.mean: 0.8525804400624999 Head.mean: 1.3928170331249998 Mouth.mean: 0.8854188166874999 Torso.mean: 0.0 \n",
      "Sentence 2: Qualifying races are held to determine starting positions and set the grid for the main event.\n",
      "\n",
      "G Visual.mean\n",
      "0.0\n",
      "Auditory.mean: 1.5138322780526317 Gustatory.mean: 0.23717831084210528 Haptic.mean: 0.9237405626842105 Interoceptive.mean: 1.0025631997368423 Olfactory.mean: 0.29217050626315794 Visual.mean: 2.7371073452631576 Foot_leg.mean: 1.1371640825263158 Hand_arm.mean: 1.454826260263158 Head.mean: 2.1604995342631583 Mouth.mean: 1.2644555966842106 Torso.mean: 0.0 \n",
      "Sentence 3: Grid position can play a significant role in outcome due to strategy around pit stop timing among other factors.\n",
      "\n",
      "Y Mouth.mean\n",
      "0.0\n",
      "Auditory.mean: 1.810462918045455 Gustatory.mean: 0.47313663763636366 Haptic.mean: 1.020436073818182 Interoceptive.mean: 1.3186869651363637 Olfactory.mean: 0.5879183835 Visual.mean: 2.1831526205909095 Foot_leg.mean: 1.0539708227727274 Hand_arm.mean: 1.5544921796363638 Head.mean: 2.6037704555909094 Mouth.mean: 1.9022486027727274 Torso.mean: 0.0 \n",
      "Sentence 4: You'll learn how they use strategy like how they choose what kind of tires they want to use during the competition.\n",
      "\n",
      "Z Olfactory.mean\n",
      "0.0\n",
      "Auditory.mean: 1.4541224062105262 Gustatory.mean: 0.7313645309473685 Haptic.mean: 0.8919620387368422 Interoceptive.mean: 1.0832213725789475 Olfactory.mean: 0.7482022910526315 Visual.mean: 1.522938958578947 Foot_leg.mean: 0.5733437555263159 Hand_arm.mean: 0.8661900972105261 Head.mean: 1.575642706368421 Mouth.mean: 0.9415310104210525 Torso.mean: 0.0 \n",
      "Sentence 5: Zandvoort will be good experience but it won't have the same sense of history as Le Man</s>\n",
      "\n",
      "F Mouth.mean\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import hashlib\n",
    "\n",
    "\n",
    "def secure_hash_to_numbers(input_string, range_list):\n",
    "    hashed_bytes = hashlib.sha256(input_string.encode()).digest()\n",
    "    \n",
    "\n",
    "    num_numbers = len(range_list)\n",
    "    hashed_integers = [int.from_bytes(hashed_bytes[i:i+4], byteorder='big') for i in range(0, num_numbers * 4, 4)]\n",
    "\n",
    "    #cast hash to integer, then use modulo to map to required range\n",
    "    \n",
    "    result_numbers = []\n",
    "    for i in range(num_numbers):\n",
    "        range_min, range_max = range_list[i]\n",
    "        integer = hashed_integers[i]\n",
    "        mapped_number = (integer % (range_max - range_min + 1)) + range_min\n",
    "        result_numbers.append(mapped_number)\n",
    "    \n",
    "    return result_numbers\n",
    "\n",
    "\n",
    "input_string  = 'The 24 Hours of Le Mans is a endurance race that takes place at the Circuit de la Sarthe, near the town of Le Mans, France.'\n",
    "range_list = [(0, 10), (0, 25)] \n",
    "# Load the English language model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    doc = nlp(text)\n",
    "    sentences = [sent.text for sent in doc.sents]\n",
    "    return sentences\n",
    "\n",
    "def get_words_in_sentence(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    words = [token.text for token in doc if not token.is_punct and not token.is_space]\n",
    "    return words\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv('Lancaster_sensorimotor_norms_for_39707_words.csv', header=0)  #the header is in the first row\n",
    "\n",
    "shared.sensorimotor = df.set_index('Word').T.to_dict('dict')\n",
    "shared.classes = ['Auditory.mean', 'Gustatory.mean','Haptic.mean','Interoceptive.mean','Olfactory.mean','Visual.mean','Foot_leg.mean','Hand_arm.mean','Head.mean','Mouth.mean','Torso.mean']\n",
    "\n",
    "\n",
    "\n",
    "sentences = split_into_sentences(reply)\n",
    "for idx, sentence in enumerate(sentences, start=1):\n",
    "    generated_numbers = secure_hash_to_numbers(sentence, range_list)\n",
    "\n",
    "\n",
    "    \n",
    "    #print(generated_numbers)\n",
    "    \n",
    "\n",
    "    word_list = get_words_in_sentence(sentence)\n",
    "    #print(word_list)\n",
    "\n",
    "    value_counts = {'Interoceptive.mean': 0.0, 'Mouth': 0.0,  'Visual': 0.0, 'Auditory': 0.0, 'Hand_arm': 0.0, 'Head': 0.0}\n",
    "\n",
    "    values = {'Auditory.mean': 0.0, 'Gustatory.mean': 0.0,'Haptic.mean': 0.0,'Interoceptive.mean': 0.0,'Olfactory.mean': 0.0,'Visual.mean': 0.0,'Foot_leg.mean': 0.0,'Hand_arm.mean': 0.0,'Head.mean': 0.0,'Mouth.mean': 0.0,'Torso.mean': 0.0}\n",
    "\n",
    "    print(values['Auditory.mean'])\n",
    "    for key in word_list:\n",
    "        if key.upper() in shared.sensorimotor:\n",
    "            for i in range(10):\n",
    "                values[shared.classes[i]] += shared.sensorimotor[key.upper()][shared.classes[i]]\n",
    "            #value_counts[shared.sensorimotor[key.upper()]] += 1\n",
    "\n",
    "    for value, count in values.items():\n",
    "        print(f\"{value}: {count/len(word_list)} \", end=\"\")\n",
    "\n",
    "    print()\n",
    "    print(f\"Sentence {idx}: {sentence}\")\n",
    "    print()\n",
    "    print(chr(ord('A') + generated_numbers[1]), shared.classes[generated_numbers[0]] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'e', 'n', 'r', 's'], ['t', 'e', 's', 'o', 'r'], ['u', 't', 's', 'e', 'i'], ['e', 'i', 't', 'n', 'a'], ['t', 'e', 'r', 'i', 'a'], ['a', 'e', 't', 'n', 'm'], ['e', 'i', 't', 'a', 'o'], ['t', 'e', 'i', 'o', 'h'], ['e', 'n', 'i', 'u', 's'], ['e', 'n', 'i', 'a', 'g'], ['e', 'r', 'a', 'n', 'o'], ['a', 'e', 'n', 't', 'o'], ['e', 't', 'i', 'o', 'p']]\n"
     ]
    }
   ],
   "source": [
    "print(most_common_letters(reply,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'U', 'G', 'R', 'I', 'Z', 'T', 'U', 'G', 'R', 'R', 'Z']\n",
      "[['e', 'n', 'a', 'r', 's'], ['t', 's', 'e', 'n', 'r'], ['e', 't', 'i', 'r', 'o'], ['e', 'i', 't', 'n', 'r'], ['e', 't', 'i', 'r', 'a'], ['a', 'e', 't', 'n', 's'], ['e', 't', 'a', 'o', 'i'], ['t', 'e', 'i', 'n', 'o'], ['e', 'n', 'u', 's', 't'], ['e', 'n', 'a', 'r', 't'], ['e', 'r', 't', 'a', 'o'], ['a', 'e', 'n', 't', 'o'], []]\n"
     ]
    }
   ],
   "source": [
    "translated = 'The 24 Hours of Le Mans is a world-renowned endurance sports car race held annually in Le Mans, France. Unlike most other motorsport events, which usually consist of short sprint races that last only a few minutes or hours, the 24 Hours of Le Mans is a true test for the drivers and their machines, spanning an entire day and night. GT engines are built to maintain high power levels for long periods of time without failure, unlike supercars that have tremendous power but a much shorter life under such conditions. Race cars designed for this competition must be lightweight, aerodynamic and highly efficient in terms of fuel consumption and tire wear. In addition, driver strategy plays a critical role in determining the winner, as teams must carefully manage their drivers changes and pit strategies throughout the race to ensure their car remains competitive from start to finish. Zero waste and maximum performance are essential aspects that make the Le Mans race a fascinating challenge and a great success for any team that can take home the trophy at the end of the race. To achieve the goal of waste reduction, organizations such as the Automobile Club de l Ouest (ACO), which organizes the event, have taken various initiatives to reduce the environmental impact of the race. Understanding these factors underscores the importance of optimizing through technology to achieve the best result with the least negative impact on the environment, while maintaining the thrill and excitement associated with top-level motorsports competition. GT engines used in such events must be carefully tuned and matched to ensure they run efficiently during the grueling duration of the race without causing unnecessarily harmful emissions or excessive fuel consumption. Race regulations also play an important role in encouraging engine designers to develop more energy-efficient engines that produce less waste and pollutants during the race. Research into advanced materials for better aerodynamics or lighter weight supports efforts to create greener racing experiences for future generations. Zero waste and maximum performance are achievable goals that can coexist and even reinforce each other when approached with innovative and forward-thinking approaches that take into account all relevant factors affecting automotive mechanics and dynamics at major racing events such as the 24 Hours of Le Mans.'\n",
    "print(first_letters(translated))\n",
    "print(most_common_letters(translated,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Human: Explain in detail: What is the 24 Hours of Le Mans? ### Assistant:\n",
      "--------------------\n",
      " The 24 Hours of Le Mans is a endurance race that takes place at the Circuit de la Sarthe, near the town of Le Mans, France.\n",
      "[2, 16]\n",
      "Q\n",
      "Qualifying races are held to determine starting positions and set the grid for the main event.\n",
      "[1, 6]\n",
      "G\n",
      "Grid positions and the specific cars and drivers participating are determined by the qualifying results and the specific class of the car being entered into the competition.\n",
      "[4, 23]\n",
      "X\n",
      "X P\n",
      "The race itself take approximately 24 hours to complete with teams consisting of two or three drivers making pit stops as needed during the course of the race.\n",
      "[0, 16]\n",
      "Q\n",
      "Output generated in 35.29 seconds (14.14 tokens/s, 499 tokens, context 24, seed 0)\n",
      " The 24 Hours of Le Mans is a endurance race that takes place at the Circuit de la Sarthe, near the town of Le Mans, France. Qualifying races are held\n",
      "to determine starting positions and set the grid for the main event. Grid positions and the specific cars and drivers participating are determined by\n",
      "the qualifying results and the specific class of the car being entered into the competition. X P The race itself take approximately 24 hours to\n",
      "complete with teams consisting of two or three drivers making pit stops as needed during the course of the race. Qualifying lasts around one day prior\n",
      "to start racing on another day with different weather condition each year depending on season it may rain during this race causing additional\n",
      "challenges due to track conditions change overnight between practice sessions leading up to race day itself can vary greatly based on weather among\n",
      "other factors that make this race even more difficult than any other race out there in worldwide circuit racing calendar schedule every June since\n",
      "first organized in July 1923 by Jean Bugatti brother of founder company Bugatti who designed original circuit layout himself with assistance from his\n",
      "father in late May same date every single summer since it all begin with only few hundred people in attendance in those days it grew rapidly through\n",
      "post war era with many famous driver name participation throughout century long existence till present day with current format maintaining much\n",
      "historical tradition that made it legendary event in international sports car racing scene with huge following fan base across planet earth with some\n",
      "even come visit site see it happen in real life with their own eyes in presence daylight with big crowd in attendace every single round it happen in\n",
      "every single summer since it all begin in mid century modern age with lot more technology available these days with safety standard in top level with\n",
      "most advance medical facility available on site in case accident occur during race event itself with lots more added feature that make it even more\n",
      "grand scale event in term of organization structure setup with massive amount budget spend on it every single edition with new technology upgrade\n",
      "every single edition with lot more media coverage with global audience in term of TV viewership number increasing steadily over last couple decades\n",
      "with new digital platform open up new way in term of online streaming service availability with wide range variety package deal option available with\n",
      "various price point target market segment aimed towards different group audience with different level financial capability in term of pay TV\n",
      "subscription cost with different channel package selection option available with different provider network in region where it stream available\n"
     ]
    }
   ],
   "source": [
    "question = \"### Human: Explain in detail: What is the 24 Hours of Le Mans? ### Assistant:\"\n",
    "\n",
    "\n",
    "generate_params = {\n",
    "    'max_new_tokens' : 500,\n",
    "    'add_bos_token' : False,\n",
    "    'truncation_length' : 2048,\n",
    "    'custom_stopping_strings' : [\"### Human:\", \"Human:\", \"user:\"],\n",
    "    'ban_eos_token' : False,\n",
    "    'skip_special_tokens' : False,\n",
    "    'do_sample': True,\n",
    "    'temperature': 0.7,\n",
    "    'top_p': 0.1,\n",
    "    'typical_p': 1,\n",
    "    'repetition_penalty': 1.176,\n",
    "    'encoder_repetition_penalty': 1,\n",
    "    'top_k': 40,\n",
    "    'num_beams': 1,\n",
    "    'penalty_alpha': 0,\n",
    "    'min_length': 0,\n",
    "    'length_penalty': 1,\n",
    "    'no_repeat_ngram_size': 0,\n",
    "    'early_stopping': False,\n",
    "    'seed' : 0,\n",
    "}\n",
    "shared.delta_char = 5.00\n",
    "shared.delta_first = 50.0\n",
    "shared.code = \"tugraz\"\n",
    "\n",
    "shared.secret_key = [0,0]\n",
    "reply = generate_reply(question, generate_params)\n",
    "\n",
    "wrapped_string = \"\\n\".join(textwrap.wrap(reply, width=150))\n",
    "print(wrapped_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "### Human: Are cats or dogs better in climbing? ### Assistant:\n",
      "--------------------\n",
      "Output generated in 5.40 seconds (14.45 tokens/s, 78 tokens, context 17, seed 0)\n",
      "  It depends on the cat and dog. Some cats are very good at climbing, while others may not be as skilled. Meanwhile, some dogs are also capable of\n",
      "climbing to different heights depending on their breed and training. Effective communication with your child can help them understand that every\n",
      "animal has its own unique abilities and characteristics. Keep reading for more tips!</s>\n"
     ]
    }
   ],
   "source": [
    "question = \"### Human: Are cats or dogs better in climbing? ### Assistant:\"\n",
    "\n",
    "\n",
    "generate_params = {\n",
    "    'max_new_tokens' : 200,\n",
    "    'add_bos_token' : False,\n",
    "    'truncation_length' : 2048,\n",
    "    'custom_stopping_strings' : [\"### Human:\", \"Human:\", \"user:\"],\n",
    "    'ban_eos_token' : False,\n",
    "    'skip_special_tokens' : False,\n",
    "    'do_sample': True,\n",
    "    'temperature': 0.7,\n",
    "    'top_p': 0.1,\n",
    "    'typical_p': 1,\n",
    "    'repetition_penalty': 1.176,\n",
    "    'encoder_repetition_penalty': 1,\n",
    "    'top_k': 40,\n",
    "    'num_beams': 1,\n",
    "    'penalty_alpha': 0,\n",
    "    'min_length': 0,\n",
    "    'length_penalty': 1,\n",
    "    'no_repeat_ngram_size': 0,\n",
    "    'early_stopping': False,\n",
    "    'seed' : 0,\n",
    "}\n",
    "shared.delta = 6.00\n",
    "shared.delta_first = 5000.0\n",
    "shared.code = \"bsmek\"\n",
    "reply = generate_reply(question, generate_params)\n",
    "\n",
    "wrapped_string = \"\\n\".join(textwrap.wrap(reply, width=150))\n",
    "print(wrapped_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'S', 'M', 'E', 'K', 's']\n",
      "[['d', 't', 'e'], ['e', 's', 'o'], ['e', 'n', 'i'], ['i', 'e', 't'], ['e', 'r', 'p'], ['s']]\n"
     ]
    }
   ],
   "source": [
    "print(first_letters(reply))\n",
    "print(most_common_letters(reply, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "76556886ee06879003f8d22dd3357c6a34e06eae87f95849600f64be34531086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
